{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment 3: Presentation of EU procurement networks**\n",
    "\n",
    "Author: Kai Foerster <br>\n",
    "ID: 214288 <br>\n",
    "Date: 23 November 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer and References:\n",
    "This work would not have been possible without EU procurement data provided under: https://networks.skewed.de/net/eu_procurements_alt. <br>\n",
    "Much of the interpretation is based on work presented in: Wachs, J., Fazekas, M. & Kertész, J. Corruption risk in contracting markets: a network science perspective. Int J Data Sci Anal 12, 45–60 (2021). https://doi.org/10.1007/s41060-019-00204-1 <br>\n",
    "Finally, this work would not be possible without intense discussion between classmates and through the help of online forums, and OpenAI's ChatGPT which has helped in debugging and describing the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, we examine the networks of public procurement contracts across various EU nations, drawing on a portion of the dataset used by Wachs, Fazekas, and Kertész in their 2020 study, \"Corruption risk in contracting markets: a network science perspective.\" The complete eu_procurements_alt dataset encompasses 234 networks, each depicting the yearly procurement activities of 26 European countries over the period from 2008 to 2016. This information originates from the Tenders Electronic Daily (TED), which is the EU's official portal for public procurement. Each network consists of issuers and winners of procurement contracts.  Each of these networks is structured as a bipartite graph, with edges symbolizing the contract awards between issuers and winners. To proceed with our analysis, additional steps will be taken to properly handle the bipartite structure inherent in these networks. <br>\n",
    "\n",
    "An integral part of our analysis will involve exploring the temporal dynamics of these networks. By examining the networks over time, we can gain insights into how the relationships and structures within these procurement systems evolve, potentially revealing patterns or trends in the data. Furthermore, we will compare these real-world networks to established network models, such as the Barabási–Albert model, to understand better how they conform to or deviate from theoretical expectations. This comparison will enable us to contextualize our findings within the broader landscape of network theory. Additionally, link prediction techniques will be employed to forecast potential future connections within these networks, offering a predictive lens through which we can assess the networks' future development and identify potential areas of risk or concern. This comprehensive approach, encompassing temporal analysis, theoretical comparison, and predictive modeling, will provide a robust framework for understanding the complex web of interactions within EU public procurement networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation and choice of countries and years\n",
    "\n",
    "While the comprehensive dataset includes data for 26 EU countries, this analysis narrows its focus to four specific countries: **xxx**, **Cyprus**, **Denmark**, and **Bulgaria**. The rationale for this selection is twofold: Firstly, these countries have comparatively smaller network sizes, which simplifies the computational process. Secondly, by analyzing only the years **xxx** and **xxx**, we cover a significant span of time while also reducing complexity. This approach strikes a balance between computational feasibility and the breadth of the analysis.\n",
    "\n",
    "In the context of corruption indicators, like the average single bidding rate used by Wachs, Fazekas, and Kertész, the chosen countries offer a diverse range of network behaviors. Cyprus and Bulgaria are included for their higher perceived levels of corruption, potentially offering insights into how such traits manifest in network structure. Conversely, Denmark, often considered a standard for low corruption levels, and Austria, which sits in the middle, provide contrasting examples. The selection aims to yield a better understanding of network properties in relation to different corruption levels, with the possibility of extending the analysis to additional countries and years for a more comprehensive study in the future.\n",
    "\n",
    "![Wachs, Fazekas, and Kertész (2021) |  Fig 1](attachment:Figure 1.png)\n",
    "\n",
    "Figure 1: Single-bidding rates on procurement contracts on TED, 2008–2016 by country, retrieved from Wachs et al. (2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and manipulating the data for further analysis\n",
    "Note on running this .ipynb file: This file is running using graph-tool installed on the wsl:Ubuntu (Linux for Windows). Before running this file you will need to install graph-tool to your PC (different methods for Windows and Mac) or configure graph-tool on Google Colab. Below you find commented out, code to configure graph-tool in Google Colab. Instructions on how to install graph-tool on Windows or Mac can be found on the graph-tool website: https://graph-tool.skewed.de/static/doc/index.html#installing-graph-tool (Last accessed: 8 November 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !echo \"deb http://downloads.skewed.de/apt jammy main\" >> /etc/apt/sources.list\n",
    "# !apt-key adv --keyserver keyserver.ubuntu.com --recv-key 612DEFB798507F25\n",
    "# !apt-get update\n",
    "# !apt-get install python3-graph-tool python3-matplotlib python3-cairo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !apt purge python3-cairo\n",
    "# !apt install libcairo2-dev pkg-config python3-dev\n",
    "# !pip install --force-reinstall pycairo\n",
    "# !pip install zstandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import graph tool libraries\n",
    "import graph_tool.all as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import geopandas as gpd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data on eu procurement contracts from Netzschleuder using graph tool and save the networks in the dictionary datasets\n",
    "\n",
    "# Select the countries and years you want to retrieve\n",
    "countries_years = [\n",
    "    ('AT', '2008'),\n",
    "    ('BG', '2008'),\n",
    "    ('CY', '2008'),\n",
    "    ('DK', '2008'),\n",
    "    ('AT', '2016'),\n",
    "    ('BG', '2016'),\n",
    "    ('CY', '2016'),\n",
    "    ('DK', '2016')\n",
    "]\n",
    "\n",
    "# Create a dictionary to hold your data\n",
    "datasets = {}\n",
    "\n",
    "# Iterate over each country/year pair and retrieve the corresponding dataset\n",
    "for country_code, year in countries_years:\n",
    "    dataset_name = f\"{country_code}_{year}\"  # This will be the key, e.g., 'AT_2016'\n",
    "    full_dataset_name = f\"eu_procurements_alt/{dataset_name}\"  # This is the full path used to retrieve the dataset from Netzschleuder\n",
    "    datasets[dataset_name] = gt.collection.ns[full_dataset_name]\n",
    "\n",
    "# Now we have a dictionary where the keys are 'AT_2016', 'CY_2008', etc., and the values are the data you've retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the graph-tool networks stored in datasets to networkx networks stored in datasets_nx\n",
    "# Note: Given that graph-tool and networkx are different libraries, we need to convert the graph-tool networks to networkx networks\n",
    "#       in order to use networkx functions. We need the networkx function bipartite.projected_graph() to compute the issuer and winner\n",
    "#       projections. We also need the networkx function bipartite.is_bipartite() to check whether a graph is bipartite. Doing this\n",
    "#       conversion is a bit cumbersome, but it's the only way to use networkx functions on graph-tool graphs. The equivalent functions\n",
    "#       in graph-tool do not exist or must be implemented manually.\n",
    "\n",
    "# Initialize the new dictionary to hold networkx datasets, saved in datasets_nx\n",
    "datasets_nx = {}\n",
    "\n",
    "for dataset_name, g_tool_graph in datasets.items():\n",
    "    # Initialize a new networkx graph for the current dataset\n",
    "    G_nx = nx.Graph()\n",
    "\n",
    "    # Add vertices and their attributes to the networkx graph\n",
    "    for v in g_tool_graph.vertices():\n",
    "        # Here, 'v_prop' is a dictionary of the vertex properties\n",
    "        v_prop = {prop: g_tool_graph.vp[prop][v] for prop in g_tool_graph.vertex_properties.keys()}\n",
    "        G_nx.add_node(v, **v_prop)\n",
    "\n",
    "    # Add edges and their attributes to the networkx graph\n",
    "    for e in g_tool_graph.edges():\n",
    "        # Here, 'e_prop' is a dictionary of the edge properties\n",
    "        e_prop = {prop: g_tool_graph.ep[prop][e] for prop in g_tool_graph.edge_properties.keys()}\n",
    "        G_nx.add_edge(e.source(), e.target(), **e_prop)\n",
    "\n",
    "    # Add the networkx graph to the new datasets dictionary\n",
    "    datasets_nx[dataset_name] = G_nx\n",
    "\n",
    "# Now `datasets_nx` contains all the networkx graphs corresponding to the graph-tool graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the issuer and winner projections using networkx functions. Then convert to projections in networkx format\n",
    "# back to graph-tool format and save the networks in the dictionary datasets_prj. In the dictionary datasets_prj,\n",
    "# the keys are the names of the projections and the values are the projections themselves. The keys are named after\n",
    "# country name, year, and projection type (issuer or winner). For example, the key 'AT_2016_issuer' corresponds to\n",
    "# the issuer projection of the network for Austria in 2016.\n",
    "\n",
    "\n",
    "datasets_prj = {}  # This dictionary will store the projections\n",
    "\n",
    "# Function to create and return both issuer and winner projections from the eu procurement bipartite graphs\n",
    "def create_projections(G):\n",
    "    issuers_set = {n for n, d in G.nodes(data=True) if d['label'].endswith('_i')}\n",
    "    winners_set = {n for n, d in G.nodes(data=True) if d['label'].endswith('_w')}\n",
    "\n",
    "    # Create the bipartite projections\n",
    "    issuer_projection = bipartite.projected_graph(G, issuers_set)\n",
    "    winner_projection = bipartite.projected_graph(G, winners_set)\n",
    "\n",
    "    return issuer_projection, winner_projection\n",
    "\n",
    "# Function to convert a networkx graph to a graph-tool graph\n",
    "def convert_networkx_to_graphtool(G_nx, name_description):\n",
    "    G_gt = Graph(directed=False)\n",
    "    pos_property = G_gt.new_vertex_property(\"vector<double>\")\n",
    "    label_property = G_gt.new_vertex_property(\"string\")\n",
    "    vertex_map = {node: G_gt.add_vertex() for node in G_nx}\n",
    "    for node, data in G_nx.nodes(data=True):\n",
    "        v = vertex_map[node]\n",
    "        pos_property[v] = data.get('_pos', [0.0, 0.0])\n",
    "        label_property[v] = data['label']\n",
    "    for u, v in G_nx.edges():\n",
    "        G_gt.add_edge(vertex_map[u], vertex_map[v])\n",
    "\n",
    "    # Set the graph name and description properties\n",
    "    G_gt.graph_properties[\"name\"] = G_gt.new_graph_property(\"string\", name_description[0])\n",
    "    G_gt.graph_properties[\"description\"] = G_gt.new_graph_property(\"string\", name_description[1])\n",
    "\n",
    "    return G_gt, pos_property, label_property\n",
    "\n",
    "# Loop over each network in datasets_nx\n",
    "for dataset_key, G_nx in datasets_nx.items():\n",
    "    # Split the key to get country and year\n",
    "    country, year = dataset_key.split('_')\n",
    "\n",
    "    # Create the projections\n",
    "    issuer_projection, winner_projection = create_projections(G_nx)\n",
    "\n",
    "    # Convert projections to graph-tool format\n",
    "    name_description = (f\"eu_procurements_alt ({country}_{year}_issuer)\",\n",
    "                        \"Issuer projection of the bipartite graph\")\n",
    "    datasets_prj[f\"{country}_{year}_issuer\"], _, _ = convert_networkx_to_graphtool(issuer_projection, name_description)\n",
    "\n",
    "    name_description = (f\"eu_procurements_alt ({country}_{year}_winner)\",\n",
    "                        \"Winner projection of the bipartite graph\")\n",
    "    datasets_prj[f\"{country}_{year}_winner\"], _, _ = convert_networkx_to_graphtool(winner_projection, name_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw a graph-tool graph using the edge properties 'count' and 'pctSingleBid'. Here, 'count' is the number of contracts\n",
    "# between two nodes and 'pctSingleBid' is the percentage of contracts between two nodes that were single-bid contracts. 'count' is used\n",
    "# as weight for the edge pen width and 'pctSingleBid' is used to color the edges where the edges become more red as the percentage of\n",
    "# single-bid contracts increases, i.e. goes from 0 to 1. The vertex color is determined by the vertex type, i.e. 'issuer' or 'winner'.\n",
    "# The vertex type is determined by the vertex label, which ends with '_i' for issuers and '_w' for winners. The vertex outline is black\n",
    "# for all vertices. The vertex pen width is set to 1.2. The function returns a dictionary with the drawing parameters.\n",
    "\n",
    "def draw_weighted_colored_graph(u, edge_color_property_name='edge_color'):\n",
    "    \"\"\"\n",
    "    Prepares edge color, pen width, and vertex color based on 'count', 'pctSingleBid',\n",
    "    and vertex type ('issuer' or 'winner').\n",
    "    Designed to be used within gt.graph_draw.\n",
    "    :param u: The graph for which the drawing parameters are being prepared.\n",
    "    :param edge_color_property_name: The name to be assigned to the new edge color property.\n",
    "    :return: A dictionary with the edge_color, edge_pen_width, vertex_fill_color, and vertex_outline properties.\n",
    "    \"\"\"\n",
    "    # Retrieve the 'count' and 'pctSingleBid' edge properties\n",
    "    edge_count = u.ep[\"count\"]\n",
    "    edge_pctSingleBid = u.ep[\"pctSingleBid\"]\n",
    "\n",
    "    # Create a new edge property for the matplotlib color mapping\n",
    "    edge_color = u.new_edge_property('vector<double>')\n",
    "    u.ep[edge_color_property_name] = edge_color\n",
    "\n",
    "    # Create color maps and normalization instance for edges\n",
    "    cmap = plt.get_cmap('coolwarm')\n",
    "    norm = colors.Normalize(vmin=0, vmax=1)  # 'pctSingleBid' is between 0 and 1\n",
    "\n",
    "    # Assign colors to edges based on 'pctSingleBid' values\n",
    "    for e in u.edges():\n",
    "        normalized_value = norm(edge_pctSingleBid[e])\n",
    "        edge_color[e] = cmap(normalized_value)\n",
    "\n",
    "    # Prepare vertex color properties\n",
    "    vertex_fill_color = u.new_vertex_property('vector<double>')\n",
    "    vertex_outline = u.new_vertex_property('vector<double>')  # For the boundary\n",
    "\n",
    "    # Check the vertex 'label' property and assign colors accordingly\n",
    "    for v in u.vertices():\n",
    "        label = u.vp.label[v]\n",
    "        if label.endswith(\"_i\"):  # Check if the vertex label ends with '_i'\n",
    "            vertex_fill_color[v] = [0.5, 0.5, 0.5, 1]  # Gray for issuers\n",
    "        elif label.endswith(\"_w\"):  # Check if the vertex label ends with '_w'\n",
    "            vertex_fill_color[v] = [1, 1, 1, 1]  # White for winners\n",
    "        vertex_outline[v] = [0, 0, 0, 1]  # Black outline for all vertices\n",
    "\n",
    "    # Prepare the dictionary with drawing parameters\n",
    "    drawing_parameters = {\n",
    "        'edge_color': edge_color,\n",
    "        'edge_pen_width': gt.prop_to_size(edge_count, mi=0.5, ma=25, power=1),\n",
    "        'vertex_fill_color': vertex_fill_color,\n",
    "        'vertex_color': vertex_outline,  # This is for the boundary\n",
    "        'vertex_pen_width': 1.2  # Adjust the pen width as needed\n",
    "    }\n",
    "\n",
    "    return drawing_parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to established network models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction\n",
    "\n",
    "Link prediction in network analysis is a task where you predict which nodes in a network are likely to form a connection. This can be useful in various domains, such as social networks, biology, and information networks. Python libraries like NetworkX and graph-tool offer tools and algorithms to facilitate this task. Here's a basic overview of how you can perform link prediction using these libraries. <br>\n",
    "\n",
    "In a bipartite network, the nodes are divided into two disjoint sets, and every edge connects a node from one set to a node from the other set. In your case, one set consists of issuers and the other of winners, and an edge represents a contract awarded from an issuer to a winner. When doing link prediction in such a network, you're right that there are inherent restrictions: issuers should only be connected to winners and not to other issuers, and similarly, winners should only be connected to issuers. <br>\n",
    "\n",
    "For link prediction in bipartite networks, the same general methods (like Common Neighbors, Jaccard Coefficient, etc.) can be used, but with a focus on predicting links between the two different sets of nodes. Here's how you can adapt the approach:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NetworkX\n",
    "NetworkX is a Python library for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. It has several built-in functions that can be used for link prediction. Common strategies include:\n",
    "\n",
    "**Common Neighbors**: Two nodes are more likely to form a link if they have many common neighbors. <br>\n",
    "**Jaccard Coefficient**: Similar to common neighbors but normalized by the total number of neighbors. <br>\n",
    "**Adamic/Adar Index**: Weighs common neighbors by their degree. <br>\n",
    "**Preferential Attachment**: Nodes with higher degree are more likely to form links. <br>\n",
    "\n",
    "NetworkX has support for bipartite networks and includes some tools that can be useful. However, when you calculate metrics like common neighbors or Jaccard coefficients, you should only consider pairs of nodes from different sets (i.e., an issuer and a winner, but never two issuers or two winners).\n",
    "\n",
    "Here's an example using NetworkX, adapted for a bipartite network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## general code for link prediction\n",
    "import networkx as nx\n",
    "\n",
    "# Create a graph\n",
    "G = nx.Graph()\n",
    "# Add some nodes and edges\n",
    "# ...\n",
    "\n",
    "# Common Neighbors\n",
    "for u, v, p in nx.common_neighbors(G, u, v):\n",
    "    print(f\"({u}, {v}) -> {p}\")\n",
    "\n",
    "# Jaccard Coefficient\n",
    "for u, v, p in nx.jaccard_coefficient(G):\n",
    "    print(f\"({u}, {v}) -> {p}\")\n",
    "\n",
    "# Adamic/Adar Index\n",
    "for u, v, p in nx.adamic_adar_index(G):\n",
    "    print(f\"({u}, {v}) -> {p}\")\n",
    "\n",
    "# Preferential Attachment\n",
    "for u, v, p in nx.preferential_attachment(G):\n",
    "    print(f\"({u}, {v}) -> {p}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## specific to bipartite graphs\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "# Create a bipartite graph\n",
    "B = nx.Graph()\n",
    "# Add nodes with the bipartite attribute\n",
    "# Assume 0 for issuers and 1 for winners\n",
    "# ...\n",
    "\n",
    "# Example: Add nodes and edges\n",
    "# B.add_node('Issuer1', bipartite=0)\n",
    "# B.add_node('Winner1', bipartite=1)\n",
    "# B.add_edge('Issuer1', 'Winner1')\n",
    "# ...\n",
    "\n",
    "# Identify the two sets of nodes\n",
    "issuers, winners = bipartite.sets(B)\n",
    "\n",
    "# Common Neighbors (only considering edges between issuers and winners)\n",
    "for issuer in issuers:\n",
    "    for winner in winners:\n",
    "        common = len(set(B.neighbors(issuer)) & set(B.neighbors(winner)))\n",
    "        print(f\"({issuer}, {winner}) -> {common} common neighbors\")\n",
    "\n",
    "# Other metrics like Jaccard Coefficient can be calculated similarly\n",
    "# ensuring that the pairs are always one issuer and one winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Considerations\n",
    "\n",
    "1. **Projection**: Sometimes, it's useful to create a projection of the bipartite network. This means creating two separate networks: one for issuers and one for winners, where nodes are connected if they share a common partner in the other set. However, for direct link prediction between issuers and winners, you usually don't need this step.\n",
    "\n",
    "2. **Custom Algorithms**: Depending on your specific requirements or the characteristics of your network, you might need to develop custom link prediction algorithms. This could involve adapting existing algorithms or creating new metrics that are particularly suited to the structure and dynamics of your network.\n",
    "\n",
    "3. **Data Preprocessing**: Ensure your data accurately represents the bipartite nature of the network. Any errors in the classification of nodes (as either issuers or winners) can significantly impact the results of your link prediction analysis.\n",
    "\n",
    "4. **Validation**: It's essential to validate your predictions, if possible, by comparing them with actual data (e.g., contracts awarded after the period covered by your dataset). This can help you assess the effectiveness of your chosen methods and refine your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using graph-tool\n",
    "graph-tool is another Python library for manipulation and statistical analysis of graphs. It's known for its efficiency, thanks to its C++ core. However, it doesn't have as many built-in link prediction functions as NetworkX. You often need to implement these algorithms yourself. But here's a basic template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "\n",
    "# Create a graph\n",
    "g = gt.Graph()\n",
    "# Add some vertices and edges\n",
    "# ...\n",
    "\n",
    "# Implement a link prediction algorithm\n",
    "# For example, you might calculate common neighbors manually\n",
    "def common_neighbors(g, u, v):\n",
    "    neighbors_u = set(g.vertex(u).out_neighbours())\n",
    "    neighbors_v = set(g.vertex(v).out_neighbours())\n",
    "    return len(neighbors_u & neighbors_v)\n",
    "\n",
    "# Iterate over non-edges and predict links\n",
    "for u in g.vertices():\n",
    "    for v in g.vertices():\n",
    "        if u != v and not g.edge(u, v):\n",
    "            score = common_neighbors(g, u, v)\n",
    "            print(f\"({u}, {v}) -> {score}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
